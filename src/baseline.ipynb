{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-17T21:48:54.946865Z",
     "iopub.status.busy": "2025-04-17T21:48:54.946680Z",
     "iopub.status.idle": "2025-04-17T21:49:21.971859Z",
     "shell.execute_reply": "2025-04-17T21:49:21.971111Z",
     "shell.execute_reply.started": "2025-04-17T21:48:54.946847Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phani\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:49:21.973163Z",
     "iopub.status.busy": "2025-04-17T21:49:21.972654Z",
     "iopub.status.idle": "2025-04-17T21:49:21.977000Z",
     "shell.execute_reply": "2025-04-17T21:49:21.976267Z",
     "shell.execute_reply.started": "2025-04-17T21:49:21.973141Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"tbs17/MathBERT\"  \n",
    "MAX_LENGTH = 256\n",
    "BATCH_SIZE = 16\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:49:21.978336Z",
     "iopub.status.busy": "2025-04-17T21:49:21.977999Z",
     "iopub.status.idle": "2025-04-17T21:49:22.143124Z",
     "shell.execute_reply": "2025-04-17T21:49:22.142197Z",
     "shell.execute_reply.started": "2025-04-17T21:49:21.978305Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    2618\n",
       "1    2439\n",
       "5    1827\n",
       "4    1712\n",
       "2    1039\n",
       "3     368\n",
       "6     100\n",
       "7      86\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:49:22.145553Z",
     "iopub.status.busy": "2025-04-17T21:49:22.145282Z",
     "iopub.status.idle": "2025-04-17T21:49:22.162372Z",
     "shell.execute_reply": "2025-04-17T21:49:22.161531Z",
     "shell.execute_reply.started": "2025-04-17T21:49:22.145532Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:49:22.163888Z",
     "iopub.status.busy": "2025-04-17T21:49:22.163602Z",
     "iopub.status.idle": "2025-04-17T21:49:22.170095Z",
     "shell.execute_reply": "2025-04-17T21:49:22.169502Z",
     "shell.execute_reply.started": "2025-04-17T21:49:22.163866Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df['Question']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-17T21:49:22.171342Z",
     "iopub.status.busy": "2025-04-17T21:49:22.171029Z",
     "iopub.status.idle": "2025-04-17T21:49:46.080181Z",
     "shell.execute_reply": "2025-04-17T21:49:46.079093Z",
     "shell.execute_reply.started": "2025-04-17T21:49:22.171312Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install textattack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:49:46.081687Z",
     "iopub.status.busy": "2025-04-17T21:49:46.081358Z",
     "iopub.status.idle": "2025-04-17T21:51:36.739998Z",
     "shell.execute_reply": "2025-04-17T21:51:36.739306Z",
     "shell.execute_reply.started": "2025-04-17T21:49:46.081649Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import random\n",
    "import re\n",
    "from textattack.augmentation import Augmenter\n",
    "from textattack.transformations import (\n",
    "    WordSwapRandomCharacterDeletion,\n",
    "    WordSwapChangeLocation\n",
    ")\n",
    "from textattack.transformations import CompositeTransformation\n",
    "\n",
    "class MathAugmenter:\n",
    "    def __init__(self):\n",
    "        self.num_augments = 2\n",
    "        transformation = CompositeTransformation([\n",
    "            WordSwapRandomCharacterDeletion(random_one=True),\n",
    "            WordSwapChangeLocation()\n",
    "        ])\n",
    "        self.augmenter = Augmenter(\n",
    "            transformation=transformation,\n",
    "            transformations_per_example=1  # Generate 1 augmented version per call\n",
    "        )\n",
    "\n",
    "    def augment_math_problem(self, text):\n",
    "        \"\"\"Augment while preserving mathematical structure\"\"\"\n",
    "        try:\n",
    "            equations = re.findall(r'\\$(.*?)\\$', text, re.DOTALL)\n",
    "            placeholders = [f' EQUATION_{i} ' for i in range(len(equations))]\n",
    "            \n",
    "            # Create template with placeholders\n",
    "            template = re.sub(r'\\$(.*?)\\$', lambda m: placeholders.pop(0), text)\n",
    "            \n",
    "            # Get list of augmented texts\n",
    "            augmented_texts = self.augmenter.augment(template)\n",
    "            \n",
    "            # Restore equations in all augmented versions\n",
    "            processed = []\n",
    "            for aug_text in augmented_texts:\n",
    "                for i, eq in enumerate(equations):\n",
    "                    aug_text = aug_text.replace(f'EQUATION_{i}', f'${eq}$')\n",
    "                processed.append(aug_text)\n",
    "                \n",
    "            return processed\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Augmentation failed for text: {text[:50]}... | Error: {e}\")\n",
    "            return [text]  # Return original as fallback\n",
    "\n",
    "# Usage for minority classes (3,6,7)\n",
    "minority_classes = [6, 7]\n",
    "augmenter = MathAugmenter()\n",
    "\n",
    "for class_id in minority_classes:\n",
    "    class_samples = train_df[train_df['label'] == class_id]['Question'].tolist()\n",
    "    augmented_samples = []\n",
    "    \n",
    "    for sample in class_samples:\n",
    "        # Get multiple augmented versions\n",
    "        augmented_versions = augmenter.augment_math_problem(sample)\n",
    "        augmented_samples.extend(augmented_versions[:3])\n",
    "        \n",
    "    # Add to training data\n",
    "    new_rows = pd.DataFrame({\n",
    "        'Question': augmented_samples,\n",
    "        'label': [class_id] * len(augmented_samples)\n",
    "    })\n",
    "    train_df = pd.concat([train_df, new_rows], ignore_index=True)\n",
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:51:36.741413Z",
     "iopub.status.busy": "2025-04-17T21:51:36.740755Z",
     "iopub.status.idle": "2025-04-17T21:51:36.748488Z",
     "shell.execute_reply": "2025-04-17T21:51:36.747568Z",
     "shell.execute_reply.started": "2025-04-17T21:51:36.741389Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df[train_df['label'] == 7]['Question']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:51:36.749709Z",
     "iopub.status.busy": "2025-04-17T21:51:36.749390Z",
     "iopub.status.idle": "2025-04-17T21:51:36.766710Z",
     "shell.execute_reply": "2025-04-17T21:51:36.765942Z",
     "shell.execute_reply.started": "2025-04-17T21:51:36.749680Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_data(train_df, test_df):\n",
    "    tr = train_df.copy()\n",
    "    te = test_df.copy()\n",
    "    \n",
    "    def clean_math_text(text):\n",
    "        # Preserve mathematical notation\n",
    "        text = re.sub(r'\\$(.*?)\\$', r' [MATH] \\1 [MATH] ', text)\n",
    "        text = re.sub(r'\\\\\\w+', lambda m: ' ' + m.group(0) + ' ', text)\n",
    "        return text.strip()\n",
    "    \n",
    "    tr['cleaned'] = tr['Question'].apply(clean_math_text)\n",
    "    te['cleaned'] = te['Question'].apply(clean_math_text)\n",
    "    tr.drop(columns=['Question'], inplace = True)\n",
    "    te.drop(columns=['Question'], inplace = True)\n",
    "    \n",
    "    return tr, te\n",
    "\n",
    "class MathDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            max_length=MAX_LENGTH,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(self.labels[idx])\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:51:36.767806Z",
     "iopub.status.busy": "2025-04-17T21:51:36.767590Z",
     "iopub.status.idle": "2025-04-17T21:51:36.788073Z",
     "shell.execute_reply": "2025-04-17T21:51:36.787203Z",
     "shell.execute_reply.started": "2025-04-17T21:51:36.767782Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_mathbert():\n",
    "    train, test = load_data(train_df, test_df)\n",
    "    \n",
    "    # Initialize tokenizer with math special tokens\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    tokenizer.add_special_tokens({'additional_special_tokens': ['[MATH]']})\n",
    "    \n",
    "    # Prepare datasets\n",
    "    test_dataset = MathDataset(\n",
    "        test['cleaned'].tolist(), \n",
    "        [0]*len(test), \n",
    "        tokenizer\n",
    "    )\n",
    "    \n",
    "    # Cross-validation setup\n",
    "    N_SPLITS=3\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS)\n",
    "    all_preds = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(\n",
    "        train['cleaned'], train['label']\n",
    "    )):\n",
    "        print(f\"\\nTraining Fold {fold+1}/{N_SPLITS}\")\n",
    "        \n",
    "        # Model initialization\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            MODEL_NAME,\n",
    "            num_labels=8,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "        \n",
    "        # Training arguments\n",
    "        args = TrainingArguments(\n",
    "            num_train_epochs = 5,\n",
    "            output_dir=f'./fold_{fold}',\n",
    "            evaluation_strategy='epoch',\n",
    "            save_strategy='epoch',\n",
    "            save_total_limit=1,\n",
    "            learning_rate=2e-5,\n",
    "            per_device_train_batch_size=16,\n",
    "            per_device_eval_batch_size=32,\n",
    "            fp16=True,\n",
    "            gradient_accumulation_steps=1,\n",
    "            dataloader_pin_memory=True,\n",
    "            dataloader_num_workers=2,\n",
    "            logging_dir='./logs',\n",
    "            logging_steps=100,\n",
    "            report_to='none',\n",
    "            warmup_ratio=0.1,\n",
    "            weight_decay=0.01,\n",
    "            seed=42,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model='f1_micro'\n",
    ")\n",
    "        \n",
    "        # Trainer setup\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=args,\n",
    "            train_dataset=MathDataset(\n",
    "                train.iloc[train_idx]['cleaned'].tolist(),\n",
    "                train.iloc[train_idx]['label'].values,\n",
    "                tokenizer\n",
    "            ),\n",
    "            eval_dataset=MathDataset(\n",
    "                train.iloc[val_idx]['cleaned'].tolist(),\n",
    "                train.iloc[val_idx]['label'].values,\n",
    "                tokenizer\n",
    "            ),\n",
    "            compute_metrics=lambda p: {\n",
    "                'f1_micro': f1_score(p.label_ids, p.predictions.argmax(-1), average='micro')\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Training\n",
    "        trainer.train()\n",
    "        \n",
    "        # Prediction\n",
    "        fold_preds = trainer.predict(test_dataset).predictions.argmax(-1)\n",
    "        all_preds.append(fold_preds)\n",
    "        print(f\"\\nFold {fold+1} Predictions Sample:\", fold_preds[:5])\n",
    "        print(f\"Class Distribution:\", np.bincount(fold_preds))\n",
    "\n",
    "        #final_preds, _ = mode(all_preds, axis=1)\n",
    "        #final_preds = final_preds.flatten().astype(int)\n",
    "\n",
    "        #submission = pd.DataFrame({\n",
    "        #    'id': test_df['id'].values,\n",
    "        #    'label': final_preds\n",
    "        #})\n",
    "        #print(submission)\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Ensemble predictions\n",
    "    all_preds_array = np.array(all_preds)\n",
    "    \n",
    "    # Calculate mode ACROSS FOLDS (axis=0)\n",
    "    final_preds, _ = mode(all_preds_array, axis=0)\n",
    "    final_preds = final_preds.flatten().astype(int)\n",
    "    \n",
    "    # Create submission\n",
    "    submission = pd.DataFrame({\n",
    "        'id': test['id'].values,\n",
    "        'label': final_preds\n",
    "    })\n",
    "    submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T21:51:36.789139Z",
     "iopub.status.busy": "2025-04-17T21:51:36.788866Z",
     "iopub.status.idle": "2025-04-17T21:51:36.807903Z",
     "shell.execute_reply": "2025-04-17T21:51:36.807161Z",
     "shell.execute_reply.started": "2025-04-17T21:51:36.789112Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#train_dummy, test_dummy = load_data(train_df, test_df)\n",
    "#train_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-17T23:18:25.488Z",
     "iopub.execute_input": "2025-04-17T21:51:36.809163Z",
     "iopub.status.busy": "2025-04-17T21:51:36.808857Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_mathbert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-17T23:18:25.496Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('output/submission.csv')\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11615683,
     "sourceId": 97669,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
